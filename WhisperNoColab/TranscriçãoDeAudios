{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"qC0Xkm5LCxnb"},"outputs":[{"name":"stdout","output_type":"stream","text":["üîÑ Carregando modelo Whisper. Isso pode levar alguns minutos...\n"]},{"name":"stderr","output_type":"stream","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 461M/461M [00:12\u003c00:00, 40.2MiB/s]\n"]},{"name":"stdout","output_type":"stream","text":["‚úÖ Modelo carregado com sucesso!\n","\n","üîä API ativa em: https://a62dcc7d4236.ngrok-free.app/transcribe\n","üìå Use Ctrl+C para encerrar\n","\n"," * Serving Flask app '__main__'\n"," * Debug mode: off\n"]},{"name":"stderr","output_type":"stream","text":["INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n"," * Running on all addresses (0.0.0.0)\n"," * Running on http://127.0.0.1:5000\n"," * Running on http://172.28.0.12:5000\n","INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n","/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n","  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n","INFO:werkzeug:127.0.0.1 - - [28/Aug/2025 13:30:15] \"POST /transcribe HTTP/1.1\" 200 -\n","/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n","  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n","INFO:werkzeug:127.0.0.1 - - [28/Aug/2025 13:37:56] \"POST /transcribe HTTP/1.1\" 200 -\n","/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n","  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n","INFO:werkzeug:127.0.0.1 - - [28/Aug/2025 13:49:33] \"POST /transcribe HTTP/1.1\" 200 -\n","/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n","  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n","INFO:werkzeug:127.0.0.1 - - [28/Aug/2025 13:57:13] \"POST /transcribe HTTP/1.1\" 200 -\n","/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n","  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n","INFO:werkzeug:127.0.0.1 - - [28/Aug/2025 14:04:53] \"POST /transcribe HTTP/1.1\" 200 -\n"]}],"source":["#Passo 5, execu√ß√£o final\n","from flask import Flask, request, jsonify\n","from pyngrok import ngrok\n","import whisper\n","import os\n","import tempfile\n","import subprocess\n","\n","# Configura√ß√£o inicial do Flask\n","app = Flask(__name__)\n","\n","# 1. Carregamento do Modelo Whisper\n","print(\"üîÑ Carregando modelo Whisper. Isso pode levar alguns minutos...\")\n","model = whisper.load_model(\"small\")  # Vers√£o balanceada entre precis√£o e performance\n","print(\"‚úÖ Modelo carregado com sucesso!\")\n","\n","# 2. Constantes de Configura√ß√£o\n","MAX_DURATION = 600  # 10 minutos (em segundos)\n","SUPPORTED_AUDIO = ('.mp3', '.wav', '.ogg', '.m4a')\n","SUPPORTED_VIDEO = ('.mp4', '.mov', '.avi')\n","ALLOWED_EXTENSIONS = SUPPORTED_AUDIO + SUPPORTED_VIDEO\n","\n","# 3. Fun√ß√µes Auxiliares\n","def extract_audio(video_path, audio_output=\"audio.wav\"):\n","    \"\"\"Converte v√≠deo para √°udio usando FFmpeg\"\"\"\n","    command = [\n","        'ffmpeg',\n","        '-i', video_path,\n","        '-vn', '-acodec', 'pcm_s16le',\n","        '-ar', '16000', '-ac', '1',\n","        '-y', audio_output  # -y sobrescreve se existir\n","    ]\n","    subprocess.run(command, check=True)\n","    return audio_output\n","\n","def get_duration(file_path):\n","    \"\"\"Obt√©m dura√ß√£o do arquivo em segundos\"\"\"\n","    result = subprocess.run([\n","        'ffprobe',\n","        '-i', file_path,\n","        '-show_entries', 'format=duration',\n","        '-v', 'quiet',\n","        '-of', 'csv=p=0'\n","    ], capture_output=True, text=True)\n","    return float(result.stdout.strip())\n","\n","# 4. Rota Principal\n","@app.route('/transcribe', methods=['POST'])\n","def transcribe_audio():\n","    \"\"\"Endpoint para processar √°udio/v√≠deo\"\"\"\n","    with tempfile.TemporaryDirectory() as temp_dir:\n","        try:\n","            # Verifica√ß√£o b√°sica\n","            if 'file' not in request.files:\n","                return jsonify({\"error\": \"Envie um arquivo como 'file'\"}), 400\n","\n","            file = request.files['file']\n","            if not file.filename.lower().endswith(ALLOWED_EXTENSIONS):\n","                return jsonify({\n","                    \"error\": \"Formato n√£o suportado\",\n","                    \"allowed_extensions\": ALLOWED_EXTENSIONS\n","                }), 400\n","\n","            # Salva o arquivo temporariamente\n","            temp_path = os.path.join(temp_dir, file.filename)\n","            file.save(temp_path)\n","\n","            # Verifica√ß√£o de dura√ß√£o\n","            duration = get_duration(temp_path)\n","            if duration \u003e MAX_DURATION:\n","                return jsonify({\n","                    \"error\": f\"Dura√ß√£o m√°xima excedida ({MAX_DURATION//60}min)\",\n","                    \"duration\": f\"{duration:.2f}s\"\n","                }), 400\n","\n","            # Processamento de v√≠deo (se necess√°rio)\n","            if file.filename.lower().endswith(SUPPORTED_VIDEO):\n","                audio_path = os.path.join(temp_dir, \"extracted_audio.wav\")\n","                extract_audio(temp_path, audio_path)\n","            else:\n","                audio_path = temp_path\n","\n","            # Transcri√ß√£o com par√¢metros otimizados\n","            result = model.transcribe(\n","                audio_path,\n","                language=\"pt\",\n","                task=\"transcribe\",  # Ou \"translate\" para traduzir\n","                initial_prompt=\"Reuni√£o corporativa, termos t√©cnicos, nomes pr√≥prios\",\n","                temperature=0.2  # Reduz criatividade para maior precis√£o\n","            )\n","\n","            return jsonify({\n","                \"text\": result[\"text\"],\n","                \"language\": result[\"language\"],\n","                \"duration\": f\"{duration:.2f}s\",\n","                \"segments\": [{\n","                    \"start\": s[\"start\"],\n","                    \"end\": s[\"end\"],\n","                    \"text\": s[\"text\"]\n","                } for s in result.get(\"segments\", [])]\n","            })\n","\n","        except subprocess.CalledProcessError as e:\n","            return jsonify({\n","                \"error\": \"Erro no processamento do arquivo\",\n","                \"details\": str(e)\n","            }), 500\n","        except Exception as e:\n","            return jsonify({\n","                \"error\": \"Erro interno\",\n","                \"details\": str(e)\n","            }), 500\n","        finally:\n","            # Limpeza garantida\n","            if 'temp_dir' in locals():\n","                for f in os.listdir(temp_dir):\n","                    os.unlink(os.path.join(temp_dir, f))\n","\n","# 5. Inicializa√ß√£o Segura\n","if __name__ == '__main__':\n","    # Configura ngrok (certifique-se de ter executado !ngrok authtoken SEU_TOKEN)\n","    public_url = ngrok.connect(5000).public_url\n","    print(f\"\\nüîä API ativa em: {public_url}/transcribe\")\n","    print(\"üìå Use Ctrl+C para encerrar\\n\")\n","\n","    # Mant√©m a sess√£o ativa\n","    try:\n","        app.run(host='0.0.0.0', port=5000)\n","    except KeyboardInterrupt:\n","        print(\"\\nüõë Servidor encerrado\")\n","        ngrok.kill()  # Fecha o t√∫nel"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-7qOIuXvVNte"},"outputs":[],"source":["from flask import Flask, request, jsonify\n","from pyngrok import ngrok\n","import whisper\n","import os\n","import tempfile\n","#Vers√£o 1 do codigo, funciona apenas para transcrever audio!\n","\n","# Configura√ß√£o inicial do Flask\n","app = Flask(__name__)\n","\n","# Carrega o modelo do Whisper uma √∫nica vez ao iniciar\n","print(\"üîÑ Carregando modelo Whisper. Isso pode levar alguns minutos...\")\n","model = whisper.load_model(\"small\")\n","print(\"‚úÖ Modelo carregado com sucesso!\")\n","\n","# Rota da API para processar √°udio\n","@app.route('/process', methods=['POST'])\n","def process_audio():\n","    # Cria um diret√≥rio tempor√°rio para o arquivo de √°udio\n","    with tempfile.TemporaryDirectory() as temp_dir:\n","        try:\n","            # Verifica se a requisi√ß√£o cont√©m um arquivo\n","            if 'audio' not in request.files:\n","                return jsonify({\"error\": \"Nenhum arquivo de √°udio enviado\"}), 400\n","\n","            audio_file = request.files['audio']\n","\n","            # Salva o arquivo em um local tempor√°rio\n","            audio_path = os.path.join(temp_dir, audio_file.filename)\n","            audio_file.save(audio_path)\n","\n","            # Realiza a transcri√ß√£o com o Whisper\n","            transcription = model.transcribe(audio_path, language=\"pt\")\n","\n","            # Retorna apenas o texto transcrito\n","            return jsonify({\"transcription\": transcription[\"text\"]})\n","\n","        except Exception as e:\n","            # Em caso de erro, retorna a mensagem\n","            return jsonify({\"error\": str(e)}), 500\n","        finally:\n","            # Garante que o arquivo tempor√°rio seja removido\n","            if 'audio_path' in locals():\n","                os.unlink(audio_path)\n","\n","# Inicia o servidor Flask e cria o t√∫nel ngrok\n","if __name__ == '__main__':\n","    # Certifique-se de que o seu token ngrok est√° configurado\n","    # A linha com o token deve ser executada separadamente ou em outra c√©lula\n","\n","    # Cria o t√∫nel e obt√©m a URL p√∫blica\n","    public_url = ngrok.connect(5000).public_url\n","    print(f\" * API acess√≠vel em: {public_url}/process\")\n","\n","    # Inicia o servidor\n","    app.run(host='0.0.0.0', port=5000)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18356,"status":"ok","timestamp":1756387557082,"user":{"displayName":"Marwan Nabil Nouwaihed","userId":"03741089778521294940"},"user_tz":180},"id":"xb019BbgEZIB","outputId":"50f6b92c-d75d-49b2-ae73-99b73d4e5864"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting ffmpeg-python\n","  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from ffmpeg-python) (1.0.0)\n","Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n","Installing collected packages: ffmpeg-python\n","Successfully installed ffmpeg-python-0.2.0\n","Requirement already satisfied: watchdog in /usr/local/lib/python3.12/dist-packages (6.0.0)\n"]}],"source":["#Em quarto roda este:\n","!pip install ffmpeg-python  # Para controle program√°tico do FFmpeg\n","!pip install watchdog      # Para monitorar arquivos tempor√°rios"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22506,"status":"ok","timestamp":1756387538708,"user":{"displayName":"Marwan Nabil Nouwaihed","userId":"03741089778521294940"},"user_tz":180},"id":"jLzrCzGBS9yN","outputId":"a18e6c5d-4925-4eb0-f3cd-82ae94bb105f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting openai-whisper\n","  Downloading openai_whisper-20250625.tar.gz (803 kB)\n","\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/803.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m716.8/803.2 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.7.0)\n","Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.60.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.0.2)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.11.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.8.0+cu126)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (4.67.1)\n","Requirement already satisfied: triton\u003e=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (3.4.0)\n","Requirement already satisfied: setuptools\u003e=40.8.0 in /usr/local/lib/python3.12/dist-packages (from triton\u003e=2-\u003eopenai-whisper) (75.2.0)\n","Requirement already satisfied: llvmlite\u003c0.44,\u003e=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba-\u003eopenai-whisper) (0.43.0)\n","Requirement already satisfied: regex\u003e=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken-\u003eopenai-whisper) (2024.11.6)\n","Requirement already satisfied: requests\u003e=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken-\u003eopenai-whisper) (2.32.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch-\u003eopenai-whisper) (3.19.1)\n","Requirement already satisfied: typing-extensions\u003e=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch-\u003eopenai-whisper) (4.15.0)\n","Requirement already satisfied: sympy\u003e=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch-\u003eopenai-whisper) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch-\u003eopenai-whisper) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-\u003eopenai-whisper) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-\u003eopenai-whisper) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch-\u003eopenai-whisper) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch-\u003eopenai-whisper) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch-\u003eopenai-whisper) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch-\u003eopenai-whisper) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch-\u003eopenai-whisper) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch-\u003eopenai-whisper) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch-\u003eopenai-whisper) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch-\u003eopenai-whisper) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch-\u003eopenai-whisper) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch-\u003eopenai-whisper) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch-\u003eopenai-whisper) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch-\u003eopenai-whisper) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch-\u003eopenai-whisper) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch-\u003eopenai-whisper) (1.11.1.6)\n","Requirement already satisfied: charset_normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.12/dist-packages (from requests\u003e=2.26.0-\u003etiktoken-\u003eopenai-whisper) (3.4.3)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.12/dist-packages (from requests\u003e=2.26.0-\u003etiktoken-\u003eopenai-whisper) (3.10)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests\u003e=2.26.0-\u003etiktoken-\u003eopenai-whisper) (2.5.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests\u003e=2.26.0-\u003etiktoken-\u003eopenai-whisper) (2025.8.3)\n","Requirement already satisfied: mpmath\u003c1.4,\u003e=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy\u003e=1.13.3-\u003etorch-\u003eopenai-whisper) (1.3.0)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2-\u003etorch-\u003eopenai-whisper) (3.0.2)\n","Building wheels for collected packages: openai-whisper\n","  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=b484e8aa81557cd1e60520f0f815f28225fa8a954d1fbde20efed19a5c1bc7f6\n","  Stored in directory: /root/.cache/pip/wheels/61/d2/20/09ec9bef734d126cba375b15898010b6cc28578d8afdde5869\n","Successfully built openai-whisper\n","Installing collected packages: openai-whisper\n","Successfully installed openai-whisper-20250625\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n","0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"]}],"source":["#Em terceiro roda este:\n","!pip install openai-whisper  # Modelo de transcri√ß√£o\n","!sudo apt install ffmpeg     # Processamento de √°udio/v√≠deo"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1621,"status":"ok","timestamp":1756387516196,"user":{"displayName":"Marwan Nabil Nouwaihed","userId":"03741089778521294940"},"user_tz":180},"id":"YTNONsU_mpWt","outputId":"547bd05d-1120-4155-dad0-c1f75ac01574"},"outputs":[{"name":"stdout","output_type":"stream","text":["Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"]}],"source":["#Em segundo roda este\n","!ngrok authtoken 319C0zRSTSZdefNrYb7iQ1hAII6_7xT2c721NTZ6jQZ8Vwnxy  # Obtenha em https://dashboard.ngrok.com/get-started/your-authtoken (ainda para a API)"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12868,"status":"ok","timestamp":1756387514564,"user":{"displayName":"Marwan Nabil Nouwaihed","userId":"03741089778521294940"},"user_tz":180},"id":"yM_PjTnNw_La","outputId":"32089872-6c76-4b27-a976-506fe36cff3b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pyngrok\n","  Downloading pyngrok-7.3.0-py3-none-any.whl.metadata (8.1 kB)\n","Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (3.1.2)\n","Requirement already satisfied: PyYAML\u003e=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.2)\n","Requirement already satisfied: blinker\u003e=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask) (1.9.0)\n","Requirement already satisfied: click\u003e=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask) (8.2.1)\n","Requirement already satisfied: itsdangerous\u003e=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask) (2.2.0)\n","Requirement already satisfied: jinja2\u003e=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.6)\n","Requirement already satisfied: markupsafe\u003e=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask) (3.0.2)\n","Requirement already satisfied: werkzeug\u003e=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.3)\n","Downloading pyngrok-7.3.0-py3-none-any.whl (25 kB)\n","Installing collected packages: pyngrok\n","Successfully installed pyngrok-7.3.0\n"]}],"source":["#Roda primeiro este\n","!pip install pyngrok flask #Para conseguiri utilizar a API"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNlIQFgtRpp6fuGT1w6+uvx","gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}